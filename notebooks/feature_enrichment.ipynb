{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# air_passengers ramp kit - feature enrichment and extractor construction\n",
    "<i>Sylvain Tostain, 2017</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "The aim of this notebook is to provide and document a relevant feature extractor for the air_passenger RAMP kit.\n",
    "\n",
    "As introduced in the starting kit notebook, a good feature extractor is of particular relevance in this ramp kit due to the fact that the data provided is rather thin, and that we noticed in exploratory visualisations that the data seems to expose seasonality and possible special causes that ought to be understood and captured before training a model.\n",
    "\n",
    "At first, let's improt and have a look at the dataset provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching RAMP dataset to load it in a dataframe with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/train.csv.bz2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data made available are as follows, `log_PAX` being our labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DateOfDeparture      object\n",
       "Departure            object\n",
       "Arrival              object\n",
       "WeeksToDeparture    float64\n",
       "log_PAX             float64\n",
       "std_wtd             float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And an overview of the contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateOfDeparture</th>\n",
       "      <th>Departure</th>\n",
       "      <th>Arrival</th>\n",
       "      <th>WeeksToDeparture</th>\n",
       "      <th>log_PAX</th>\n",
       "      <th>std_wtd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-06-19</td>\n",
       "      <td>ORD</td>\n",
       "      <td>DFW</td>\n",
       "      <td>12.875000</td>\n",
       "      <td>12.331296</td>\n",
       "      <td>9.812647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>LAS</td>\n",
       "      <td>DEN</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>10.775182</td>\n",
       "      <td>9.466734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-05</td>\n",
       "      <td>DEN</td>\n",
       "      <td>LAX</td>\n",
       "      <td>10.863636</td>\n",
       "      <td>11.083177</td>\n",
       "      <td>9.035883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-10-09</td>\n",
       "      <td>ATL</td>\n",
       "      <td>ORD</td>\n",
       "      <td>11.480000</td>\n",
       "      <td>11.169268</td>\n",
       "      <td>7.990202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-02-21</td>\n",
       "      <td>DEN</td>\n",
       "      <td>SFO</td>\n",
       "      <td>11.450000</td>\n",
       "      <td>11.269364</td>\n",
       "      <td>9.517159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DateOfDeparture Departure Arrival  WeeksToDeparture    log_PAX   std_wtd\n",
       "0      2012-06-19       ORD     DFW         12.875000  12.331296  9.812647\n",
       "1      2012-09-10       LAS     DEN         14.285714  10.775182  9.466734\n",
       "2      2012-10-05       DEN     LAX         10.863636  11.083177  9.035883\n",
       "3      2011-10-09       ATL     ORD         11.480000  11.169268  7.990202\n",
       "4      2012-02-21       DEN     SFO         11.450000  11.269364  9.517159"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the timeframe we are adressing. This is especially usefull for the sake of data enrichment from other sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011-09-01\n",
      "2013-03-05\n"
     ]
    }
   ],
   "source": [
    "print(min(data['DateOfDeparture']))\n",
    "print(max(data['DateOfDeparture']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching the additional external dataset provided with the RAMP kit\n",
    "The dataset comes in this RAMP kit with a sample additional dataset `external_data.csv` pertaining weather data and used as sample in the kit demonstration. This data might come in handy as well, we'll take it on board too as a seed for our own `external_data.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                           object\n",
       "AirPort                        object\n",
       "Max TemperatureC                int64\n",
       "Mean TemperatureC               int64\n",
       "Min TemperatureC                int64\n",
       "Dew PointC                      int64\n",
       "MeanDew PointC                  int64\n",
       "Min DewpointC                   int64\n",
       "Max Humidity                    int64\n",
       "Mean Humidity                   int64\n",
       "Min Humidity                    int64\n",
       "Max Sea Level PressurehPa       int64\n",
       "Mean Sea Level PressurehPa      int64\n",
       "Min Sea Level PressurehPa       int64\n",
       "Max VisibilityKm                int64\n",
       "Mean VisibilityKm               int64\n",
       "Min VisibilitykM                int64\n",
       "Max Wind SpeedKm/h              int64\n",
       "Mean Wind SpeedKm/h             int64\n",
       "Max Gust SpeedKm/h            float64\n",
       "Precipitationmm                object\n",
       "CloudCover                      int64\n",
       "Events                         object\n",
       "WindDirDegrees                  int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext_data = pd.read_csv(\"../submissions/starting_kit/external_data.csv\")\n",
    "ext_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are meteo descriptors.\n",
    "\n",
    "We'll keep them but this needs extra attention on complimentary data to enrich our dataset, as it is believed to be a key success factor..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AirPort</th>\n",
       "      <th>Max TemperatureC</th>\n",
       "      <th>Mean TemperatureC</th>\n",
       "      <th>Min TemperatureC</th>\n",
       "      <th>Dew PointC</th>\n",
       "      <th>MeanDew PointC</th>\n",
       "      <th>Min DewpointC</th>\n",
       "      <th>Max Humidity</th>\n",
       "      <th>Mean Humidity</th>\n",
       "      <th>Min Humidity</th>\n",
       "      <th>Max Sea Level PressurehPa</th>\n",
       "      <th>Mean Sea Level PressurehPa</th>\n",
       "      <th>Min Sea Level PressurehPa</th>\n",
       "      <th>Max VisibilityKm</th>\n",
       "      <th>Mean VisibilityKm</th>\n",
       "      <th>Min VisibilitykM</th>\n",
       "      <th>Max Wind SpeedKm/h</th>\n",
       "      <th>Mean Wind SpeedKm/h</th>\n",
       "      <th>Max Gust SpeedKm/h</th>\n",
       "      <th>Precipitationmm</th>\n",
       "      <th>CloudCover</th>\n",
       "      <th>Events</th>\n",
       "      <th>WindDirDegrees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-09-01</td>\n",
       "      <td>ATL</td>\n",
       "      <td>35</td>\n",
       "      <td>29</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>79</td>\n",
       "      <td>56</td>\n",
       "      <td>32</td>\n",
       "      <td>1022</td>\n",
       "      <td>1019</td>\n",
       "      <td>1017</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-09-02</td>\n",
       "      <td>ATL</td>\n",
       "      <td>36</td>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>61</td>\n",
       "      <td>46</td>\n",
       "      <td>30</td>\n",
       "      <td>1019</td>\n",
       "      <td>1016</td>\n",
       "      <td>1014</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-09-03</td>\n",
       "      <td>ATL</td>\n",
       "      <td>35</td>\n",
       "      <td>29</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>64</td>\n",
       "      <td>47</td>\n",
       "      <td>30</td>\n",
       "      <td>1015</td>\n",
       "      <td>1013</td>\n",
       "      <td>1011</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-09-04</td>\n",
       "      <td>ATL</td>\n",
       "      <td>27</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>93</td>\n",
       "      <td>72</td>\n",
       "      <td>51</td>\n",
       "      <td>1014</td>\n",
       "      <td>1012</td>\n",
       "      <td>1011</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6.10</td>\n",
       "      <td>6</td>\n",
       "      <td>Rain</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-09-05</td>\n",
       "      <td>ATL</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>94</td>\n",
       "      <td>91</td>\n",
       "      <td>87</td>\n",
       "      <td>1010</td>\n",
       "      <td>1005</td>\n",
       "      <td>999</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>8</td>\n",
       "      <td>Rain-Thunderstorm</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date AirPort  Max TemperatureC  Mean TemperatureC  Min TemperatureC  \\\n",
       "0  2011-09-01     ATL                35                 29                24   \n",
       "1  2011-09-02     ATL                36                 29                22   \n",
       "2  2011-09-03     ATL                35                 29                23   \n",
       "3  2011-09-04     ATL                27                 24                22   \n",
       "4  2011-09-05     ATL                26                 24                22   \n",
       "\n",
       "   Dew PointC  MeanDew PointC  Min DewpointC  Max Humidity  Mean Humidity  \\\n",
       "0          21              18             14            79             56   \n",
       "1          17              15             14            61             46   \n",
       "2          17              16             14            64             47   \n",
       "3          22              19             16            93             72   \n",
       "4          23              22             20            94             91   \n",
       "\n",
       "   Min Humidity  Max Sea Level PressurehPa  Mean Sea Level PressurehPa  \\\n",
       "0            32                       1022                        1019   \n",
       "1            30                       1019                        1016   \n",
       "2            30                       1015                        1013   \n",
       "3            51                       1014                        1012   \n",
       "4            87                       1010                        1005   \n",
       "\n",
       "   Min Sea Level PressurehPa  Max VisibilityKm  Mean VisibilityKm  \\\n",
       "0                       1017                16                 16   \n",
       "1                       1014                16                 16   \n",
       "2                       1011                16                 16   \n",
       "3                       1011                16                 14   \n",
       "4                        999                16                 13   \n",
       "\n",
       "   Min VisibilitykM  Max Wind SpeedKm/h  Mean Wind SpeedKm/h  \\\n",
       "0                11                  19                    6   \n",
       "1                16                  24                    7   \n",
       "2                16                  19                    7   \n",
       "3                 4                  21                    9   \n",
       "4                 3                  32                   16   \n",
       "\n",
       "   Max Gust SpeedKm/h Precipitationmm  CloudCover             Events  \\\n",
       "0                26.0            0.00           3                NaN   \n",
       "1                34.0            0.00           2                NaN   \n",
       "2                26.0            0.00           4                NaN   \n",
       "3                26.0            6.10           6               Rain   \n",
       "4                45.0           16.00           8  Rain-Thunderstorm   \n",
       "\n",
       "   WindDirDegrees  \n",
       "0             129  \n",
       "1             185  \n",
       "2             147  \n",
       "3             139  \n",
       "4             149  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that Events may require one hot encoding, but this is not the place for further data exploration. Please see the dedicated notebook if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factors in Events:\n",
      "['None' 'Rain' 'Rain-Thunderstorm' 'Fog' 'Fog-Rain-Thunderstorm'\n",
      " 'Rain-Snow' 'Snow' 'Fog-Rain' 'Thunderstorm' 'Fog-Snow' 'Fog-Rain-Snow'\n",
      " 'Fog-Rain-Snow-Thunderstorm' 'Rain-Snow-Thunderstorm'\n",
      " 'Rain-Hail-Thunderstorm' 'Fog-Rain-Hail-Thunderstorm'\n",
      " 'Rain-Thunderstorm-Tornado']\n",
      "Total number of factors in Events: 16\n"
     ]
    }
   ],
   "source": [
    "ext_data['Events'] = ext_data['Events'].fillna('None')\n",
    "print(\"Factors in Events:\")\n",
    "print(ext_data['Events'].unique())\n",
    "print(\"Total number of factors in Events: {}\".format(len(ext_data['Events'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This kind of data might happen to be significant, unfortunately it is very inconveniently structured.\n",
    "\n",
    "More sophisticated encoding could be considered at a later stage, but we'll start with a simple one hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AirPort</th>\n",
       "      <th>Max TemperatureC</th>\n",
       "      <th>Mean TemperatureC</th>\n",
       "      <th>Min TemperatureC</th>\n",
       "      <th>Dew PointC</th>\n",
       "      <th>MeanDew PointC</th>\n",
       "      <th>Min DewpointC</th>\n",
       "      <th>Max Humidity</th>\n",
       "      <th>Mean Humidity</th>\n",
       "      <th>Min Humidity</th>\n",
       "      <th>Max Sea Level PressurehPa</th>\n",
       "      <th>Mean Sea Level PressurehPa</th>\n",
       "      <th>Min Sea Level PressurehPa</th>\n",
       "      <th>Max VisibilityKm</th>\n",
       "      <th>Mean VisibilityKm</th>\n",
       "      <th>Min VisibilitykM</th>\n",
       "      <th>Max Wind SpeedKm/h</th>\n",
       "      <th>Mean Wind SpeedKm/h</th>\n",
       "      <th>Max Gust SpeedKm/h</th>\n",
       "      <th>Precipitationmm</th>\n",
       "      <th>CloudCover</th>\n",
       "      <th>WindDirDegrees</th>\n",
       "      <th>Fog</th>\n",
       "      <th>Fog-Rain</th>\n",
       "      <th>Fog-Rain-Hail-Thunderstorm</th>\n",
       "      <th>Fog-Rain-Snow</th>\n",
       "      <th>Fog-Rain-Snow-Thunderstorm</th>\n",
       "      <th>Fog-Rain-Thunderstorm</th>\n",
       "      <th>Fog-Snow</th>\n",
       "      <th>None</th>\n",
       "      <th>Rain</th>\n",
       "      <th>Rain-Hail-Thunderstorm</th>\n",
       "      <th>Rain-Snow</th>\n",
       "      <th>Rain-Snow-Thunderstorm</th>\n",
       "      <th>Rain-Thunderstorm</th>\n",
       "      <th>Rain-Thunderstorm-Tornado</th>\n",
       "      <th>Snow</th>\n",
       "      <th>Thunderstorm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-09-01</td>\n",
       "      <td>ATL</td>\n",
       "      <td>35</td>\n",
       "      <td>29</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>79</td>\n",
       "      <td>56</td>\n",
       "      <td>32</td>\n",
       "      <td>1022</td>\n",
       "      <td>1019</td>\n",
       "      <td>1017</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-09-02</td>\n",
       "      <td>ATL</td>\n",
       "      <td>36</td>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>61</td>\n",
       "      <td>46</td>\n",
       "      <td>30</td>\n",
       "      <td>1019</td>\n",
       "      <td>1016</td>\n",
       "      <td>1014</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-09-03</td>\n",
       "      <td>ATL</td>\n",
       "      <td>35</td>\n",
       "      <td>29</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>64</td>\n",
       "      <td>47</td>\n",
       "      <td>30</td>\n",
       "      <td>1015</td>\n",
       "      <td>1013</td>\n",
       "      <td>1011</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-09-04</td>\n",
       "      <td>ATL</td>\n",
       "      <td>27</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>93</td>\n",
       "      <td>72</td>\n",
       "      <td>51</td>\n",
       "      <td>1014</td>\n",
       "      <td>1012</td>\n",
       "      <td>1011</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6.10</td>\n",
       "      <td>6</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-09-05</td>\n",
       "      <td>ATL</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>94</td>\n",
       "      <td>91</td>\n",
       "      <td>87</td>\n",
       "      <td>1010</td>\n",
       "      <td>1005</td>\n",
       "      <td>999</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>8</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date AirPort  Max TemperatureC  Mean TemperatureC  Min TemperatureC  \\\n",
       "0 2011-09-01     ATL                35                 29                24   \n",
       "1 2011-09-02     ATL                36                 29                22   \n",
       "2 2011-09-03     ATL                35                 29                23   \n",
       "3 2011-09-04     ATL                27                 24                22   \n",
       "4 2011-09-05     ATL                26                 24                22   \n",
       "\n",
       "   Dew PointC  MeanDew PointC  Min DewpointC  Max Humidity  Mean Humidity  \\\n",
       "0          21              18             14            79             56   \n",
       "1          17              15             14            61             46   \n",
       "2          17              16             14            64             47   \n",
       "3          22              19             16            93             72   \n",
       "4          23              22             20            94             91   \n",
       "\n",
       "   Min Humidity  Max Sea Level PressurehPa  Mean Sea Level PressurehPa  \\\n",
       "0            32                       1022                        1019   \n",
       "1            30                       1019                        1016   \n",
       "2            30                       1015                        1013   \n",
       "3            51                       1014                        1012   \n",
       "4            87                       1010                        1005   \n",
       "\n",
       "   Min Sea Level PressurehPa  Max VisibilityKm  Mean VisibilityKm  \\\n",
       "0                       1017                16                 16   \n",
       "1                       1014                16                 16   \n",
       "2                       1011                16                 16   \n",
       "3                       1011                16                 14   \n",
       "4                        999                16                 13   \n",
       "\n",
       "   Min VisibilitykM  Max Wind SpeedKm/h  Mean Wind SpeedKm/h  \\\n",
       "0                11                  19                    6   \n",
       "1                16                  24                    7   \n",
       "2                16                  19                    7   \n",
       "3                 4                  21                    9   \n",
       "4                 3                  32                   16   \n",
       "\n",
       "   Max Gust SpeedKm/h Precipitationmm  CloudCover  WindDirDegrees  Fog  \\\n",
       "0                26.0            0.00           3             129    0   \n",
       "1                34.0            0.00           2             185    0   \n",
       "2                26.0            0.00           4             147    0   \n",
       "3                26.0            6.10           6             139    0   \n",
       "4                45.0           16.00           8             149    0   \n",
       "\n",
       "   Fog-Rain  Fog-Rain-Hail-Thunderstorm  Fog-Rain-Snow  \\\n",
       "0         0                           0              0   \n",
       "1         0                           0              0   \n",
       "2         0                           0              0   \n",
       "3         0                           0              0   \n",
       "4         0                           0              0   \n",
       "\n",
       "   Fog-Rain-Snow-Thunderstorm  Fog-Rain-Thunderstorm  Fog-Snow  None  Rain  \\\n",
       "0                           0                      0         0     1     0   \n",
       "1                           0                      0         0     1     0   \n",
       "2                           0                      0         0     1     0   \n",
       "3                           0                      0         0     0     1   \n",
       "4                           0                      0         0     0     0   \n",
       "\n",
       "   Rain-Hail-Thunderstorm  Rain-Snow  Rain-Snow-Thunderstorm  \\\n",
       "0                       0          0                       0   \n",
       "1                       0          0                       0   \n",
       "2                       0          0                       0   \n",
       "3                       0          0                       0   \n",
       "4                       0          0                       0   \n",
       "\n",
       "   Rain-Thunderstorm  Rain-Thunderstorm-Tornado  Snow  Thunderstorm  \n",
       "0                  0                          0     0             0  \n",
       "1                  0                          0     0             0  \n",
       "2                  0                          0     0             0  \n",
       "3                  0                          0     0             0  \n",
       "4                  1                          0     0             0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext_data_enc = ext_data\n",
    "\n",
    "ext_data_enc = ext_data_enc.join(pd.get_dummies(ext_data_enc['Events']))\n",
    "ext_data_enc = ext_data_enc.drop('Events', axis=1)\n",
    "\n",
    "# Also needed later for a graceful join with other data...\n",
    "ext_data_enc['Date'] = pd.to_datetime(ext_data_enc['Date'])\n",
    "\n",
    "ext_data_enc.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structuring the base dataset\n",
    "As seen in the visualisations and in the starting kit, it is relevant to provide some structure to the base dataset, more specifically:\n",
    "* Regarding dates, in order to allow our models to capture seasonality. Months, weeks and weekdays are probably the most relevant. We can forget about days of the month that are probably less relevant.\n",
    "* Regarding factors, we'll apply one hot encoding on departure and arrival airports.\n",
    "\n",
    "Nevertheless, we have to keep in mind that there will be a huge cost in termes of dimensions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factors in Departure:\n",
      "['ORD' 'LAS' 'DEN' 'ATL' 'SFO' 'EWR' 'IAH' 'LAX' 'DFW' 'SEA' 'JFK' 'PHL'\n",
      " 'MIA' 'DTW' 'BOS' 'MSP' 'CLT' 'MCO' 'PHX' 'LGA']\n",
      "Total number of factors in Departure: 20\n",
      "\n",
      "Factors in Arrival:\n",
      "['DFW' 'DEN' 'LAX' 'ORD' 'SFO' 'MCO' 'LAS' 'CLT' 'MSP' 'EWR' 'PHX' 'DTW'\n",
      " 'MIA' 'BOS' 'PHL' 'JFK' 'ATL' 'LGA' 'SEA' 'IAH']\n",
      "Total number of factors in Arrival: 20\n"
     ]
    }
   ],
   "source": [
    "print(\"Factors in Departure:\")\n",
    "print(data['Departure'].unique())\n",
    "print(\"Total number of factors in Departure: {}\".format(len(data['Departure'].unique())))\n",
    "\n",
    "print(\"\\nFactors in Arrival:\")\n",
    "print(data['Arrival'].unique())\n",
    "print(\"Total number of factors in Arrival: {}\".format(len(data['Arrival'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply these transformations.\n",
    "\n",
    "We'll keep weekdays and weeks, and forget about the other time series factors so far, as we see lesser interest from our visualisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Directly inspired from the starting kit notebook.\n",
    "data_enc = data\n",
    "\n",
    "# One-hot encoding of departure points, then drop of the initial feature\n",
    "data_enc = data_enc.join(pd.get_dummies(data_enc['Departure'], prefix='d'))\n",
    "data_enc = data_enc.drop('Departure', axis=1)\n",
    "\n",
    "# One-hot encoding of arrival points, then drop of the initial feature\n",
    "data_enc = data_enc.join(pd.get_dummies(data_enc['Arrival'], prefix='a'))\n",
    "data_enc = data_enc.drop('Arrival', axis=1)\n",
    "\n",
    "# One-hot encoding of temporal variables that might catch seasonalities and/or special causes\n",
    "# following http://stackoverflow.com/questions/16453644/regression-with-date-variable-using-scikit-learn\n",
    "data_enc['DateOfDeparture'] = pd.to_datetime(data_enc['DateOfDeparture'])\n",
    "\n",
    "data_enc['weekday'] = data_enc['DateOfDeparture'].dt.weekday\n",
    "data_enc = data_enc.join(pd.get_dummies(data_enc['weekday'], prefix='wd'))\n",
    "data_enc = data_enc.drop('weekday', axis=1)\n",
    "\n",
    "data_enc['week'] = data_enc['DateOfDeparture'].dt.week\n",
    "data_enc = data_enc.join(pd.get_dummies(data_enc['week'], prefix='w'))\n",
    "data_enc = data_enc.drop('week', axis=1)\n",
    "\n",
    "# Commented out : probably useless and most certainly costly in terms of dimensions...\n",
    "#\n",
    "# data_enc['year'] = data_enc['DateOfDeparture'].dt.year\n",
    "# data_enc = data_enc.join(pd.get_dummies(data_enc['year'], prefix='y'))\n",
    "#\n",
    "# data_enc['month'] = data_enc['DateOfDeparture'].dt.month\n",
    "# data_enc = data_enc.join(pd.get_dummies(data_enc['month'], prefix='m'))\n",
    "#\n",
    "# data_enc['day'] = data_enc['DateOfDeparture'].dt.day\n",
    "# data_enc = data_enc.join(pd.get_dummies(data_enc['day'], prefix='d'))\n",
    "#\n",
    "# data_enc['n_days'] = data_enc['DateOfDeparture'].apply(lambda date: (date - pd.to_datetime(\"1970-01-01\")).days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DateOfDeparture', 'WeeksToDeparture', 'log_PAX', 'std_wtd', 'd_ATL', 'd_BOS', 'd_CLT', 'd_DEN', 'd_DFW', 'd_DTW', 'd_EWR', 'd_IAH', 'd_JFK', 'd_LAS', 'd_LAX', 'd_LGA', 'd_MCO', 'd_MIA', 'd_MSP', 'd_ORD', 'd_PHL', 'd_PHX', 'd_SEA', 'd_SFO', 'a_ATL', 'a_BOS', 'a_CLT', 'a_DEN', 'a_DFW', 'a_DTW', 'a_EWR', 'a_IAH', 'a_JFK', 'a_LAS', 'a_LAX', 'a_LGA', 'a_MCO', 'a_MIA', 'a_MSP', 'a_ORD', 'a_PHL', 'a_PHX', 'a_SEA', 'a_SFO', 'wd_0', 'wd_1', 'wd_2', 'wd_3', 'wd_4', 'wd_5', 'wd_6', 'w_1', 'w_2', 'w_3', 'w_4', 'w_5', 'w_6', 'w_7', 'w_8', 'w_9', 'w_10', 'w_11', 'w_12', 'w_13', 'w_14', 'w_15', 'w_16', 'w_17', 'w_18', 'w_19', 'w_20', 'w_21', 'w_22', 'w_23', 'w_24', 'w_25', 'w_26', 'w_27', 'w_28', 'w_29', 'w_30', 'w_31', 'w_32', 'w_33', 'w_34', 'w_35', 'w_36', 'w_37', 'w_38', 'w_39', 'w_40', 'w_41', 'w_42', 'w_43', 'w_44', 'w_45', 'w_46', 'w_47', 'w_48', 'w_49', 'w_50', 'w_51', 'w_52']\n",
      "Total number of columns: 103\n"
     ]
    }
   ],
   "source": [
    "print(list(data_enc.columns))\n",
    "print(\"Total number of columns: {}\".format(len(list(data_enc.columns))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, our base dataset is prepared and ready for enrichment..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a richer external dataset\n",
    "### Introduction: data regarding public holidays\n",
    "Given the observations made through visualisations, we have collected additional data.\n",
    "\n",
    "Regarding holidays, the situation is rather complex given the fact that there is no regulated paid off days for every employer in the US. Even federal holidays are left to the discretion of the employers. We therefore adopted the following approach.\n",
    "\n",
    "So far, the following data have been captured in an excel file:\n",
    "* Statistics on paid off days, collected in 2011 by SHRM in <a href=https://www.shrm.org/hr-today/news/hr-news/Pages/paidholidaysin2011.aspx>this article</a>. Note: observances for which paid off days have been given by less than 10% of responding companies have not been retained as relevant.\n",
    "* All federal holidays plus observances retained as significant for off days, as given on <a href=https://www.timeanddate.com/holidays/us/>timeanddate.com</a>\n",
    "\n",
    "A holidays.csv file has been generated in which we aggregated, for the time period at hand:\n",
    "* Date: the date;\n",
    "* FederalHoliday: 1 if the day is a Federal Holiday, otherwise 0;\n",
    "* PaidHoliday: a float between 0 and 1, capturing the proportion of respondents in SHRM article having given a paid off day (remember however that events with lesser than 10% paid off days have been ignored);\n",
    "* Event: a text factor, describing the nature of the event taken into consideration.\n",
    "Please note that Federal Holidays on sundays are usually observed on mondays, this has been taken into account.\n",
    "\n",
    "Let's load the dataset.\n",
    "### Loading holidays.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date               object\n",
       "FederalHoliday      int64\n",
       "PaidHoliday       float64\n",
       "Event              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext_holidays = pd.read_csv(\"../data_sources/holidays.csv\")\n",
    "ext_holidays.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factors in Event:\n",
      "[nan 'labor' 'colombus' 'veterans' 'thanksgiving' 'thanksgiving_after'\n",
      " 'christmas_eve_before' 'christmas_eve' 'christmas' 'new_year_eve_before'\n",
      " 'new_year_eve' 'new_year' 'mlk_birthday' 'presidents' 'good_friday'\n",
      " 'memorial' 'independence']\n",
      "Total number of factors in Event: 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>FederalHoliday</th>\n",
       "      <th>PaidHoliday</th>\n",
       "      <th>Event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/09/2011</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02/09/2011</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03/09/2011</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04/09/2011</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05/09/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>labor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  FederalHoliday  PaidHoliday  Event\n",
       "0  01/09/2011               0         0.00    NaN\n",
       "1  02/09/2011               0         0.00    NaN\n",
       "2  03/09/2011               0         0.00    NaN\n",
       "3  04/09/2011               0         0.00    NaN\n",
       "4  05/09/2011               1         0.95  labor"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Factors in Event:\")\n",
    "print(ext_holidays['Event'].unique())\n",
    "print(\"Total number of factors in Event: {}\".format(len(ext_holidays['Event'].unique())))\n",
    "ext_holidays.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to turn the date into something useable for a join, and consider one-hot encoding for events (if we keep them).\n",
    "### Encoding parameters from holidays properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                    datetime64[ns]\n",
       "FederalHoliday                   int64\n",
       "PaidHoliday                    float64\n",
       "christmas                        uint8\n",
       "christmas_eve                    uint8\n",
       "christmas_eve_before             uint8\n",
       "colombus                         uint8\n",
       "good_friday                      uint8\n",
       "independence                     uint8\n",
       "labor                            uint8\n",
       "memorial                         uint8\n",
       "mlk_birthday                     uint8\n",
       "new_year                         uint8\n",
       "new_year_eve                     uint8\n",
       "new_year_eve_before              uint8\n",
       "presidents                       uint8\n",
       "thanksgiving                     uint8\n",
       "thanksgiving_after               uint8\n",
       "veterans                         uint8\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>FederalHoliday</th>\n",
       "      <th>PaidHoliday</th>\n",
       "      <th>christmas</th>\n",
       "      <th>christmas_eve</th>\n",
       "      <th>christmas_eve_before</th>\n",
       "      <th>colombus</th>\n",
       "      <th>good_friday</th>\n",
       "      <th>independence</th>\n",
       "      <th>labor</th>\n",
       "      <th>memorial</th>\n",
       "      <th>mlk_birthday</th>\n",
       "      <th>new_year</th>\n",
       "      <th>new_year_eve</th>\n",
       "      <th>new_year_eve_before</th>\n",
       "      <th>presidents</th>\n",
       "      <th>thanksgiving</th>\n",
       "      <th>thanksgiving_after</th>\n",
       "      <th>veterans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-09-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-09-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-09-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-09-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-09-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  FederalHoliday  PaidHoliday  christmas  christmas_eve  \\\n",
       "0 2011-09-01               0         0.00          0              0   \n",
       "1 2011-09-02               0         0.00          0              0   \n",
       "2 2011-09-03               0         0.00          0              0   \n",
       "3 2011-09-04               0         0.00          0              0   \n",
       "4 2011-09-05               1         0.95          0              0   \n",
       "\n",
       "   christmas_eve_before  colombus  good_friday  independence  labor  memorial  \\\n",
       "0                     0         0            0             0      0         0   \n",
       "1                     0         0            0             0      0         0   \n",
       "2                     0         0            0             0      0         0   \n",
       "3                     0         0            0             0      0         0   \n",
       "4                     0         0            0             0      1         0   \n",
       "\n",
       "   mlk_birthday  new_year  new_year_eve  new_year_eve_before  presidents  \\\n",
       "0             0         0             0                    0           0   \n",
       "1             0         0             0                    0           0   \n",
       "2             0         0             0                    0           0   \n",
       "3             0         0             0                    0           0   \n",
       "4             0         0             0                    0           0   \n",
       "\n",
       "   thanksgiving  thanksgiving_after  veterans  \n",
       "0             0                   0         0  \n",
       "1             0                   0         0  \n",
       "2             0                   0         0  \n",
       "3             0                   0         0  \n",
       "4             0                   0         0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext_holidays_enc = ext_holidays\n",
    "ext_holidays_enc = ext_holidays_enc.join(pd.get_dummies(ext_holidays_enc['Event']))\n",
    "ext_holidays_enc = ext_holidays_enc.drop('Event', axis=1)\n",
    "\n",
    "ext_holidays_enc['Date'] = pd.to_datetime(ext_holidays_enc['Date'], dayfirst=True)\n",
    "\n",
    "display(ext_holidays_enc.dtypes)\n",
    "ext_holidays_enc.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `ext_holidays_enc` dataframe is now ready for a join with the rest of `external_data_enc`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining weather data and public holiday data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AirPort</th>\n",
       "      <th>Max TemperatureC</th>\n",
       "      <th>Mean TemperatureC</th>\n",
       "      <th>Min TemperatureC</th>\n",
       "      <th>Dew PointC</th>\n",
       "      <th>MeanDew PointC</th>\n",
       "      <th>Min DewpointC</th>\n",
       "      <th>Max Humidity</th>\n",
       "      <th>Mean Humidity</th>\n",
       "      <th>Min Humidity</th>\n",
       "      <th>Max Sea Level PressurehPa</th>\n",
       "      <th>Mean Sea Level PressurehPa</th>\n",
       "      <th>Min Sea Level PressurehPa</th>\n",
       "      <th>Max VisibilityKm</th>\n",
       "      <th>Mean VisibilityKm</th>\n",
       "      <th>Min VisibilitykM</th>\n",
       "      <th>Max Wind SpeedKm/h</th>\n",
       "      <th>Mean Wind SpeedKm/h</th>\n",
       "      <th>Max Gust SpeedKm/h</th>\n",
       "      <th>Precipitationmm</th>\n",
       "      <th>CloudCover</th>\n",
       "      <th>WindDirDegrees</th>\n",
       "      <th>Fog</th>\n",
       "      <th>Fog-Rain</th>\n",
       "      <th>Fog-Rain-Hail-Thunderstorm</th>\n",
       "      <th>Fog-Rain-Snow</th>\n",
       "      <th>Fog-Rain-Snow-Thunderstorm</th>\n",
       "      <th>Fog-Rain-Thunderstorm</th>\n",
       "      <th>Fog-Snow</th>\n",
       "      <th>None</th>\n",
       "      <th>Rain</th>\n",
       "      <th>Rain-Hail-Thunderstorm</th>\n",
       "      <th>Rain-Snow</th>\n",
       "      <th>Rain-Snow-Thunderstorm</th>\n",
       "      <th>Rain-Thunderstorm</th>\n",
       "      <th>Rain-Thunderstorm-Tornado</th>\n",
       "      <th>Snow</th>\n",
       "      <th>Thunderstorm</th>\n",
       "      <th>FederalHoliday</th>\n",
       "      <th>PaidHoliday</th>\n",
       "      <th>christmas</th>\n",
       "      <th>christmas_eve</th>\n",
       "      <th>christmas_eve_before</th>\n",
       "      <th>colombus</th>\n",
       "      <th>good_friday</th>\n",
       "      <th>independence</th>\n",
       "      <th>labor</th>\n",
       "      <th>memorial</th>\n",
       "      <th>mlk_birthday</th>\n",
       "      <th>new_year</th>\n",
       "      <th>new_year_eve</th>\n",
       "      <th>new_year_eve_before</th>\n",
       "      <th>presidents</th>\n",
       "      <th>thanksgiving</th>\n",
       "      <th>thanksgiving_after</th>\n",
       "      <th>veterans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-09-01</td>\n",
       "      <td>ATL</td>\n",
       "      <td>35</td>\n",
       "      <td>29</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>79</td>\n",
       "      <td>56</td>\n",
       "      <td>32</td>\n",
       "      <td>1022</td>\n",
       "      <td>1019</td>\n",
       "      <td>1017</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-09-02</td>\n",
       "      <td>ATL</td>\n",
       "      <td>36</td>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>61</td>\n",
       "      <td>46</td>\n",
       "      <td>30</td>\n",
       "      <td>1019</td>\n",
       "      <td>1016</td>\n",
       "      <td>1014</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-09-03</td>\n",
       "      <td>ATL</td>\n",
       "      <td>35</td>\n",
       "      <td>29</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>64</td>\n",
       "      <td>47</td>\n",
       "      <td>30</td>\n",
       "      <td>1015</td>\n",
       "      <td>1013</td>\n",
       "      <td>1011</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-09-04</td>\n",
       "      <td>ATL</td>\n",
       "      <td>27</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>93</td>\n",
       "      <td>72</td>\n",
       "      <td>51</td>\n",
       "      <td>1014</td>\n",
       "      <td>1012</td>\n",
       "      <td>1011</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6.10</td>\n",
       "      <td>6</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-09-05</td>\n",
       "      <td>ATL</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>94</td>\n",
       "      <td>91</td>\n",
       "      <td>87</td>\n",
       "      <td>1010</td>\n",
       "      <td>1005</td>\n",
       "      <td>999</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>8</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date AirPort  Max TemperatureC  Mean TemperatureC  Min TemperatureC  \\\n",
       "0 2011-09-01     ATL                35                 29                24   \n",
       "1 2011-09-02     ATL                36                 29                22   \n",
       "2 2011-09-03     ATL                35                 29                23   \n",
       "3 2011-09-04     ATL                27                 24                22   \n",
       "4 2011-09-05     ATL                26                 24                22   \n",
       "\n",
       "   Dew PointC  MeanDew PointC  Min DewpointC  Max Humidity  Mean Humidity  \\\n",
       "0          21              18             14            79             56   \n",
       "1          17              15             14            61             46   \n",
       "2          17              16             14            64             47   \n",
       "3          22              19             16            93             72   \n",
       "4          23              22             20            94             91   \n",
       "\n",
       "   Min Humidity  Max Sea Level PressurehPa  Mean Sea Level PressurehPa  \\\n",
       "0            32                       1022                        1019   \n",
       "1            30                       1019                        1016   \n",
       "2            30                       1015                        1013   \n",
       "3            51                       1014                        1012   \n",
       "4            87                       1010                        1005   \n",
       "\n",
       "   Min Sea Level PressurehPa  Max VisibilityKm  Mean VisibilityKm  \\\n",
       "0                       1017                16                 16   \n",
       "1                       1014                16                 16   \n",
       "2                       1011                16                 16   \n",
       "3                       1011                16                 14   \n",
       "4                        999                16                 13   \n",
       "\n",
       "   Min VisibilitykM  Max Wind SpeedKm/h  Mean Wind SpeedKm/h  \\\n",
       "0                11                  19                    6   \n",
       "1                16                  24                    7   \n",
       "2                16                  19                    7   \n",
       "3                 4                  21                    9   \n",
       "4                 3                  32                   16   \n",
       "\n",
       "   Max Gust SpeedKm/h Precipitationmm  CloudCover  WindDirDegrees  Fog  \\\n",
       "0                26.0            0.00           3             129    0   \n",
       "1                34.0            0.00           2             185    0   \n",
       "2                26.0            0.00           4             147    0   \n",
       "3                26.0            6.10           6             139    0   \n",
       "4                45.0           16.00           8             149    0   \n",
       "\n",
       "   Fog-Rain  Fog-Rain-Hail-Thunderstorm  Fog-Rain-Snow  \\\n",
       "0         0                           0              0   \n",
       "1         0                           0              0   \n",
       "2         0                           0              0   \n",
       "3         0                           0              0   \n",
       "4         0                           0              0   \n",
       "\n",
       "   Fog-Rain-Snow-Thunderstorm  Fog-Rain-Thunderstorm  Fog-Snow  None  Rain  \\\n",
       "0                           0                      0         0     1     0   \n",
       "1                           0                      0         0     1     0   \n",
       "2                           0                      0         0     1     0   \n",
       "3                           0                      0         0     0     1   \n",
       "4                           0                      0         0     0     0   \n",
       "\n",
       "   Rain-Hail-Thunderstorm  Rain-Snow  Rain-Snow-Thunderstorm  \\\n",
       "0                       0          0                       0   \n",
       "1                       0          0                       0   \n",
       "2                       0          0                       0   \n",
       "3                       0          0                       0   \n",
       "4                       0          0                       0   \n",
       "\n",
       "   Rain-Thunderstorm  Rain-Thunderstorm-Tornado  Snow  Thunderstorm  \\\n",
       "0                  0                          0     0             0   \n",
       "1                  0                          0     0             0   \n",
       "2                  0                          0     0             0   \n",
       "3                  0                          0     0             0   \n",
       "4                  1                          0     0             0   \n",
       "\n",
       "   FederalHoliday  PaidHoliday  christmas  christmas_eve  \\\n",
       "0               0         0.00          0              0   \n",
       "1               0         0.00          0              0   \n",
       "2               0         0.00          0              0   \n",
       "3               0         0.00          0              0   \n",
       "4               1         0.95          0              0   \n",
       "\n",
       "   christmas_eve_before  colombus  good_friday  independence  labor  memorial  \\\n",
       "0                     0         0            0             0      0         0   \n",
       "1                     0         0            0             0      0         0   \n",
       "2                     0         0            0             0      0         0   \n",
       "3                     0         0            0             0      0         0   \n",
       "4                     0         0            0             0      1         0   \n",
       "\n",
       "   mlk_birthday  new_year  new_year_eve  new_year_eve_before  presidents  \\\n",
       "0             0         0             0                    0           0   \n",
       "1             0         0             0                    0           0   \n",
       "2             0         0             0                    0           0   \n",
       "3             0         0             0                    0           0   \n",
       "4             0         0             0                    0           0   \n",
       "\n",
       "   thanksgiving  thanksgiving_after  veterans  \n",
       "0             0                   0         0  \n",
       "1             0                   0         0  \n",
       "2             0                   0         0  \n",
       "3             0                   0         0  \n",
       "4             0                   0         0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Date columns have the same name in both dataframe, the join is straigthforward\n",
    "ext_full = pd.merge(ext_data_enc, ext_holidays_enc, how='left', left_on=['Date'], right_on=['Date'], sort=False)\n",
    "ext_full.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have an enriched external dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading airports.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Airport       object\n",
       "Town          object\n",
       "Latitude     float64\n",
       "Longitude    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext_airports = pd.read_csv(\"../data_sources/airports.csv\")\n",
    "ext_airports.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging with previous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AirPort</th>\n",
       "      <th>Max TemperatureC</th>\n",
       "      <th>Mean TemperatureC</th>\n",
       "      <th>Min TemperatureC</th>\n",
       "      <th>Dew PointC</th>\n",
       "      <th>MeanDew PointC</th>\n",
       "      <th>Min DewpointC</th>\n",
       "      <th>Max Humidity</th>\n",
       "      <th>Mean Humidity</th>\n",
       "      <th>Min Humidity</th>\n",
       "      <th>Max Sea Level PressurehPa</th>\n",
       "      <th>Mean Sea Level PressurehPa</th>\n",
       "      <th>Min Sea Level PressurehPa</th>\n",
       "      <th>Max VisibilityKm</th>\n",
       "      <th>Mean VisibilityKm</th>\n",
       "      <th>Min VisibilitykM</th>\n",
       "      <th>Max Wind SpeedKm/h</th>\n",
       "      <th>Mean Wind SpeedKm/h</th>\n",
       "      <th>Max Gust SpeedKm/h</th>\n",
       "      <th>Precipitationmm</th>\n",
       "      <th>CloudCover</th>\n",
       "      <th>WindDirDegrees</th>\n",
       "      <th>Fog</th>\n",
       "      <th>Fog-Rain</th>\n",
       "      <th>Fog-Rain-Hail-Thunderstorm</th>\n",
       "      <th>Fog-Rain-Snow</th>\n",
       "      <th>Fog-Rain-Snow-Thunderstorm</th>\n",
       "      <th>Fog-Rain-Thunderstorm</th>\n",
       "      <th>Fog-Snow</th>\n",
       "      <th>None</th>\n",
       "      <th>Rain</th>\n",
       "      <th>Rain-Hail-Thunderstorm</th>\n",
       "      <th>Rain-Snow</th>\n",
       "      <th>Rain-Snow-Thunderstorm</th>\n",
       "      <th>Rain-Thunderstorm</th>\n",
       "      <th>Rain-Thunderstorm-Tornado</th>\n",
       "      <th>Snow</th>\n",
       "      <th>Thunderstorm</th>\n",
       "      <th>FederalHoliday</th>\n",
       "      <th>PaidHoliday</th>\n",
       "      <th>christmas</th>\n",
       "      <th>christmas_eve</th>\n",
       "      <th>christmas_eve_before</th>\n",
       "      <th>colombus</th>\n",
       "      <th>good_friday</th>\n",
       "      <th>independence</th>\n",
       "      <th>labor</th>\n",
       "      <th>memorial</th>\n",
       "      <th>mlk_birthday</th>\n",
       "      <th>new_year</th>\n",
       "      <th>new_year_eve</th>\n",
       "      <th>new_year_eve_before</th>\n",
       "      <th>presidents</th>\n",
       "      <th>thanksgiving</th>\n",
       "      <th>thanksgiving_after</th>\n",
       "      <th>veterans</th>\n",
       "      <th>Airport</th>\n",
       "      <th>Town</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-09-01</td>\n",
       "      <td>ATL</td>\n",
       "      <td>35</td>\n",
       "      <td>29</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>79</td>\n",
       "      <td>56</td>\n",
       "      <td>32</td>\n",
       "      <td>1022</td>\n",
       "      <td>1019</td>\n",
       "      <td>1017</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>33.641</td>\n",
       "      <td>-84.4226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-09-02</td>\n",
       "      <td>ATL</td>\n",
       "      <td>36</td>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>61</td>\n",
       "      <td>46</td>\n",
       "      <td>30</td>\n",
       "      <td>1019</td>\n",
       "      <td>1016</td>\n",
       "      <td>1014</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>33.641</td>\n",
       "      <td>-84.4226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-09-03</td>\n",
       "      <td>ATL</td>\n",
       "      <td>35</td>\n",
       "      <td>29</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>64</td>\n",
       "      <td>47</td>\n",
       "      <td>30</td>\n",
       "      <td>1015</td>\n",
       "      <td>1013</td>\n",
       "      <td>1011</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>33.641</td>\n",
       "      <td>-84.4226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-09-04</td>\n",
       "      <td>ATL</td>\n",
       "      <td>27</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>93</td>\n",
       "      <td>72</td>\n",
       "      <td>51</td>\n",
       "      <td>1014</td>\n",
       "      <td>1012</td>\n",
       "      <td>1011</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6.10</td>\n",
       "      <td>6</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>33.641</td>\n",
       "      <td>-84.4226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-09-05</td>\n",
       "      <td>ATL</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>94</td>\n",
       "      <td>91</td>\n",
       "      <td>87</td>\n",
       "      <td>1010</td>\n",
       "      <td>1005</td>\n",
       "      <td>999</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>8</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>33.641</td>\n",
       "      <td>-84.4226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date AirPort  Max TemperatureC  Mean TemperatureC  Min TemperatureC  \\\n",
       "0 2011-09-01     ATL                35                 29                24   \n",
       "1 2011-09-02     ATL                36                 29                22   \n",
       "2 2011-09-03     ATL                35                 29                23   \n",
       "3 2011-09-04     ATL                27                 24                22   \n",
       "4 2011-09-05     ATL                26                 24                22   \n",
       "\n",
       "   Dew PointC  MeanDew PointC  Min DewpointC  Max Humidity  Mean Humidity  \\\n",
       "0          21              18             14            79             56   \n",
       "1          17              15             14            61             46   \n",
       "2          17              16             14            64             47   \n",
       "3          22              19             16            93             72   \n",
       "4          23              22             20            94             91   \n",
       "\n",
       "   Min Humidity  Max Sea Level PressurehPa  Mean Sea Level PressurehPa  \\\n",
       "0            32                       1022                        1019   \n",
       "1            30                       1019                        1016   \n",
       "2            30                       1015                        1013   \n",
       "3            51                       1014                        1012   \n",
       "4            87                       1010                        1005   \n",
       "\n",
       "   Min Sea Level PressurehPa  Max VisibilityKm  Mean VisibilityKm  \\\n",
       "0                       1017                16                 16   \n",
       "1                       1014                16                 16   \n",
       "2                       1011                16                 16   \n",
       "3                       1011                16                 14   \n",
       "4                        999                16                 13   \n",
       "\n",
       "   Min VisibilitykM  Max Wind SpeedKm/h  Mean Wind SpeedKm/h  \\\n",
       "0                11                  19                    6   \n",
       "1                16                  24                    7   \n",
       "2                16                  19                    7   \n",
       "3                 4                  21                    9   \n",
       "4                 3                  32                   16   \n",
       "\n",
       "   Max Gust SpeedKm/h Precipitationmm  CloudCover  WindDirDegrees  Fog  \\\n",
       "0                26.0            0.00           3             129    0   \n",
       "1                34.0            0.00           2             185    0   \n",
       "2                26.0            0.00           4             147    0   \n",
       "3                26.0            6.10           6             139    0   \n",
       "4                45.0           16.00           8             149    0   \n",
       "\n",
       "   Fog-Rain  Fog-Rain-Hail-Thunderstorm  Fog-Rain-Snow  \\\n",
       "0         0                           0              0   \n",
       "1         0                           0              0   \n",
       "2         0                           0              0   \n",
       "3         0                           0              0   \n",
       "4         0                           0              0   \n",
       "\n",
       "   Fog-Rain-Snow-Thunderstorm  Fog-Rain-Thunderstorm  Fog-Snow  None  Rain  \\\n",
       "0                           0                      0         0     1     0   \n",
       "1                           0                      0         0     1     0   \n",
       "2                           0                      0         0     1     0   \n",
       "3                           0                      0         0     0     1   \n",
       "4                           0                      0         0     0     0   \n",
       "\n",
       "   Rain-Hail-Thunderstorm  Rain-Snow  Rain-Snow-Thunderstorm  \\\n",
       "0                       0          0                       0   \n",
       "1                       0          0                       0   \n",
       "2                       0          0                       0   \n",
       "3                       0          0                       0   \n",
       "4                       0          0                       0   \n",
       "\n",
       "   Rain-Thunderstorm  Rain-Thunderstorm-Tornado  Snow  Thunderstorm  \\\n",
       "0                  0                          0     0             0   \n",
       "1                  0                          0     0             0   \n",
       "2                  0                          0     0             0   \n",
       "3                  0                          0     0             0   \n",
       "4                  1                          0     0             0   \n",
       "\n",
       "   FederalHoliday  PaidHoliday  christmas  christmas_eve  \\\n",
       "0               0         0.00          0              0   \n",
       "1               0         0.00          0              0   \n",
       "2               0         0.00          0              0   \n",
       "3               0         0.00          0              0   \n",
       "4               1         0.95          0              0   \n",
       "\n",
       "   christmas_eve_before  colombus  good_friday  independence  labor  memorial  \\\n",
       "0                     0         0            0             0      0         0   \n",
       "1                     0         0            0             0      0         0   \n",
       "2                     0         0            0             0      0         0   \n",
       "3                     0         0            0             0      0         0   \n",
       "4                     0         0            0             0      1         0   \n",
       "\n",
       "   mlk_birthday  new_year  new_year_eve  new_year_eve_before  presidents  \\\n",
       "0             0         0             0                    0           0   \n",
       "1             0         0             0                    0           0   \n",
       "2             0         0             0                    0           0   \n",
       "3             0         0             0                    0           0   \n",
       "4             0         0             0                    0           0   \n",
       "\n",
       "   thanksgiving  thanksgiving_after  veterans Airport     Town  Latitude  \\\n",
       "0             0                   0         0     ATL  Atlanta    33.641   \n",
       "1             0                   0         0     ATL  Atlanta    33.641   \n",
       "2             0                   0         0     ATL  Atlanta    33.641   \n",
       "3             0                   0         0     ATL  Atlanta    33.641   \n",
       "4             0                   0         0     ATL  Atlanta    33.641   \n",
       "\n",
       "   Longitude  \n",
       "0   -84.4226  \n",
       "1   -84.4226  \n",
       "2   -84.4226  \n",
       "3   -84.4226  \n",
       "4   -84.4226  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Date columns have the same name in both dataframe, the join is straigthforward\n",
    "ext_full_2 = pd.merge(ext_full, ext_airports, how='left', left_on=['AirPort'], right_on=['Airport'], sort=False)\n",
    "ext_full_2.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enriching with the distances of the trips\n",
    "Now that we have the coordinates of the airports, we'll try to compute the distances of the trips.\n",
    "\n",
    "We'll make use of a mapped version of the <a href=https://en.wikipedia.org/wiki/Haversine_formula>Haversine Formula</a>, implemented in Python as follows :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inspired from https://stackoverflow.com\n",
    "#    /questions/4913349/haversine-formula-in-python-bearing-and-distance-between-two-gps-points\n",
    "\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "def haversine(row):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # we map the rows\n",
    "    lon1 = row['D_lon']\n",
    "    lat1 = row['D_lat']\n",
    "    lon2 = row['A_lon']\n",
    "    lat2 = row['A_lat']\n",
    "    \n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 6371 # Radius of earth in kilometers. Use 3956 for miles\n",
    "    return c * r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubik/.anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AirPort</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-09-01</td>\n",
       "      <td>ATL</td>\n",
       "      <td>33.641</td>\n",
       "      <td>-84.4226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-09-02</td>\n",
       "      <td>ATL</td>\n",
       "      <td>33.641</td>\n",
       "      <td>-84.4226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-09-03</td>\n",
       "      <td>ATL</td>\n",
       "      <td>33.641</td>\n",
       "      <td>-84.4226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-09-04</td>\n",
       "      <td>ATL</td>\n",
       "      <td>33.641</td>\n",
       "      <td>-84.4226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-09-05</td>\n",
       "      <td>ATL</td>\n",
       "      <td>33.641</td>\n",
       "      <td>-84.4226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date AirPort  Latitude  Longitude\n",
       "0 2011-09-01     ATL    33.641   -84.4226\n",
       "1 2011-09-02     ATL    33.641   -84.4226\n",
       "2 2011-09-03     ATL    33.641   -84.4226\n",
       "3 2011-09-04     ATL    33.641   -84.4226\n",
       "4 2011-09-05     ATL    33.641   -84.4226"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateOfDeparture</th>\n",
       "      <th>Departure</th>\n",
       "      <th>Arrival</th>\n",
       "      <th>WeeksToDeparture</th>\n",
       "      <th>log_PAX</th>\n",
       "      <th>std_wtd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-06-19</td>\n",
       "      <td>ORD</td>\n",
       "      <td>DFW</td>\n",
       "      <td>12.875000</td>\n",
       "      <td>12.331296</td>\n",
       "      <td>9.812647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>LAS</td>\n",
       "      <td>DEN</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>10.775182</td>\n",
       "      <td>9.466734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-05</td>\n",
       "      <td>DEN</td>\n",
       "      <td>LAX</td>\n",
       "      <td>10.863636</td>\n",
       "      <td>11.083177</td>\n",
       "      <td>9.035883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-10-09</td>\n",
       "      <td>ATL</td>\n",
       "      <td>ORD</td>\n",
       "      <td>11.480000</td>\n",
       "      <td>11.169268</td>\n",
       "      <td>7.990202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-02-21</td>\n",
       "      <td>DEN</td>\n",
       "      <td>SFO</td>\n",
       "      <td>11.450000</td>\n",
       "      <td>11.269364</td>\n",
       "      <td>9.517159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DateOfDeparture Departure Arrival  WeeksToDeparture    log_PAX   std_wtd\n",
       "0      2012-06-19       ORD     DFW         12.875000  12.331296  9.812647\n",
       "1      2012-09-10       LAS     DEN         14.285714  10.775182  9.466734\n",
       "2      2012-10-05       DEN     LAX         10.863636  11.083177  9.035883\n",
       "3      2011-10-09       ATL     ORD         11.480000  11.169268  7.990202\n",
       "4      2012-02-21       DEN     SFO         11.450000  11.269364  9.517159"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateOfDeparture</th>\n",
       "      <th>Departure</th>\n",
       "      <th>Arrival</th>\n",
       "      <th>WeeksToDeparture</th>\n",
       "      <th>log_PAX</th>\n",
       "      <th>std_wtd</th>\n",
       "      <th>D_lat</th>\n",
       "      <th>D_lon</th>\n",
       "      <th>A_lat</th>\n",
       "      <th>A_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-06-19</td>\n",
       "      <td>ORD</td>\n",
       "      <td>DFW</td>\n",
       "      <td>12.875000</td>\n",
       "      <td>12.331296</td>\n",
       "      <td>9.812647</td>\n",
       "      <td>41.9796</td>\n",
       "      <td>-87.9045</td>\n",
       "      <td>32.8959</td>\n",
       "      <td>-97.0372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>LAS</td>\n",
       "      <td>DEN</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>10.775182</td>\n",
       "      <td>9.466734</td>\n",
       "      <td>36.0852</td>\n",
       "      <td>-115.1507</td>\n",
       "      <td>39.8589</td>\n",
       "      <td>-104.6733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-05</td>\n",
       "      <td>DEN</td>\n",
       "      <td>LAX</td>\n",
       "      <td>10.863636</td>\n",
       "      <td>11.083177</td>\n",
       "      <td>9.035883</td>\n",
       "      <td>39.8589</td>\n",
       "      <td>-104.6733</td>\n",
       "      <td>33.9425</td>\n",
       "      <td>-118.4090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-10-09</td>\n",
       "      <td>ATL</td>\n",
       "      <td>ORD</td>\n",
       "      <td>11.480000</td>\n",
       "      <td>11.169268</td>\n",
       "      <td>7.990202</td>\n",
       "      <td>33.6410</td>\n",
       "      <td>-84.4226</td>\n",
       "      <td>41.9796</td>\n",
       "      <td>-87.9045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-02-21</td>\n",
       "      <td>DEN</td>\n",
       "      <td>SFO</td>\n",
       "      <td>11.450000</td>\n",
       "      <td>11.269364</td>\n",
       "      <td>9.517159</td>\n",
       "      <td>39.8589</td>\n",
       "      <td>-104.6733</td>\n",
       "      <td>37.6218</td>\n",
       "      <td>-122.3790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DateOfDeparture Departure Arrival  WeeksToDeparture    log_PAX   std_wtd  \\\n",
       "0      2012-06-19       ORD     DFW         12.875000  12.331296  9.812647   \n",
       "1      2012-09-10       LAS     DEN         14.285714  10.775182  9.466734   \n",
       "2      2012-10-05       DEN     LAX         10.863636  11.083177  9.035883   \n",
       "3      2011-10-09       ATL     ORD         11.480000  11.169268  7.990202   \n",
       "4      2012-02-21       DEN     SFO         11.450000  11.269364  9.517159   \n",
       "\n",
       "     D_lat     D_lon    A_lat     A_lon  \n",
       "0  41.9796  -87.9045  32.8959  -97.0372  \n",
       "1  36.0852 -115.1507  39.8589 -104.6733  \n",
       "2  39.8589 -104.6733  33.9425 -118.4090  \n",
       "3  33.6410  -84.4226  41.9796  -87.9045  \n",
       "4  39.8589 -104.6733  37.6218 -122.3790  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DateOfDeparture     datetime64[ns]\n",
       "Departure                   object\n",
       "Arrival                     object\n",
       "WeeksToDeparture           float64\n",
       "log_PAX                    float64\n",
       "std_wtd                    float64\n",
       "D_lat                      float64\n",
       "D_lon                      float64\n",
       "A_lat                      float64\n",
       "A_lon                      float64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateOfDeparture</th>\n",
       "      <th>Departure</th>\n",
       "      <th>Arrival</th>\n",
       "      <th>WeeksToDeparture</th>\n",
       "      <th>log_PAX</th>\n",
       "      <th>std_wtd</th>\n",
       "      <th>D_lat</th>\n",
       "      <th>D_lon</th>\n",
       "      <th>A_lat</th>\n",
       "      <th>A_lon</th>\n",
       "      <th>Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-06-19</td>\n",
       "      <td>ORD</td>\n",
       "      <td>DFW</td>\n",
       "      <td>12.875000</td>\n",
       "      <td>12.331296</td>\n",
       "      <td>9.812647</td>\n",
       "      <td>41.9796</td>\n",
       "      <td>-87.9045</td>\n",
       "      <td>32.8959</td>\n",
       "      <td>-97.0372</td>\n",
       "      <td>1290.782275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>LAS</td>\n",
       "      <td>DEN</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>10.775182</td>\n",
       "      <td>9.466734</td>\n",
       "      <td>36.0852</td>\n",
       "      <td>-115.1507</td>\n",
       "      <td>39.8589</td>\n",
       "      <td>-104.6733</td>\n",
       "      <td>1008.860199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-05</td>\n",
       "      <td>DEN</td>\n",
       "      <td>LAX</td>\n",
       "      <td>10.863636</td>\n",
       "      <td>11.083177</td>\n",
       "      <td>9.035883</td>\n",
       "      <td>39.8589</td>\n",
       "      <td>-104.6733</td>\n",
       "      <td>33.9425</td>\n",
       "      <td>-118.4090</td>\n",
       "      <td>1385.066996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-10-09</td>\n",
       "      <td>ATL</td>\n",
       "      <td>ORD</td>\n",
       "      <td>11.480000</td>\n",
       "      <td>11.169268</td>\n",
       "      <td>7.990202</td>\n",
       "      <td>33.6410</td>\n",
       "      <td>-84.4226</td>\n",
       "      <td>41.9796</td>\n",
       "      <td>-87.9045</td>\n",
       "      <td>976.118298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-02-21</td>\n",
       "      <td>DEN</td>\n",
       "      <td>SFO</td>\n",
       "      <td>11.450000</td>\n",
       "      <td>11.269364</td>\n",
       "      <td>9.517159</td>\n",
       "      <td>39.8589</td>\n",
       "      <td>-104.6733</td>\n",
       "      <td>37.6218</td>\n",
       "      <td>-122.3790</td>\n",
       "      <td>1552.991274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DateOfDeparture Departure Arrival  WeeksToDeparture    log_PAX   std_wtd  \\\n",
       "0      2012-06-19       ORD     DFW         12.875000  12.331296  9.812647   \n",
       "1      2012-09-10       LAS     DEN         14.285714  10.775182  9.466734   \n",
       "2      2012-10-05       DEN     LAX         10.863636  11.083177  9.035883   \n",
       "3      2011-10-09       ATL     ORD         11.480000  11.169268  7.990202   \n",
       "4      2012-02-21       DEN     SFO         11.450000  11.269364  9.517159   \n",
       "\n",
       "     D_lat     D_lon    A_lat     A_lon     Distance  \n",
       "0  41.9796  -87.9045  32.8959  -97.0372  1290.782275  \n",
       "1  36.0852 -115.1507  39.8589 -104.6733  1008.860199  \n",
       "2  39.8589 -104.6733  33.9425 -118.4090  1385.066996  \n",
       "3  33.6410  -84.4226  41.9796  -87.9045   976.118298  \n",
       "4  39.8589 -104.6733  37.6218 -122.3790  1552.991274  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We import the useful.\n",
    "ext_coords = ext_full_2[['Date','AirPort','Latitude', 'Longitude']]\n",
    "data_dist = data\n",
    "\n",
    "# We ensure that the dates are of the same format.\n",
    "ext_coords['Date'] = pd.to_datetime(ext_coords['Date'], dayfirst = True)\n",
    "data_dist['DateOfDeparture'] = pd.to_datetime(data_dist['DateOfDeparture'], dayfirst = True)\n",
    "\n",
    "# A quick view at the data...\n",
    "display(ext_coords.head(5))\n",
    "display(data_dist.head(5))\n",
    "\n",
    "# We perform a first merge to import departure coordinates.\n",
    "data_dist = pd.merge(\n",
    "    data_dist, ext_coords,\n",
    "    how='left',\n",
    "    left_on=['DateOfDeparture', 'Departure'],\n",
    "    right_on=['Date', 'AirPort'],\n",
    "    sort=False)\n",
    "data_dist = data_dist.drop(['Date', 'AirPort'], axis=1)\n",
    "\n",
    "data_dist = data_dist.rename(\n",
    "    columns={'Latitude': 'D_lat', 'Longitude': 'D_lon'})\n",
    "\n",
    "# We perform a second merge to import arrival coordinates.\n",
    "data_dist = pd.merge(\n",
    "    data_dist, ext_coords,\n",
    "    how='left',\n",
    "    left_on=['DateOfDeparture', 'Arrival'],\n",
    "    right_on=['Date', 'AirPort'],\n",
    "    sort=False)\n",
    "data_dist = data_dist.drop(['Date', 'AirPort'], axis=1)\n",
    "\n",
    "data_dist = data_dist.rename(\n",
    "    columns={'Latitude': 'A_lat', 'Longitude': 'A_lon'})\n",
    "\n",
    "# Another view.\n",
    "display(data_dist.head(5))\n",
    "display(data_dist.dtypes)\n",
    "\n",
    "# And we apply the Haversine formula.\n",
    "data_dist['Distance'] = data_dist.apply(lambda row: haversine(row), axis=1)\n",
    "\n",
    "display(data_dist.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap-up\n",
    "We have build a first enriched dataset, that we'll test as a new submission : `iteration_0`\n",
    "\n",
    "An empty directory has been created accordingly (if not, it needs to be on your local environment)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Scrapper\n",
    "In addition to the two mandatory functions on RAMP, we captured steps necessary to produce the `external_data.csv` file in an additional `scrapper` function stored in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def scrapper(path):\n",
    "    \"\"\"This function combine data from the initial external_data.csv\n",
    "    of the starting_kit together with additional data sources and\n",
    "    serialise the dataframe in external.data.csv in the target directory.\n",
    "    \n",
    "    Argument:\n",
    "    path : directory where to save external_data.csv\"\"\"\n",
    "\n",
    "    # Import weather data from the original external_data.csv file\n",
    "    weather = pd.read_csv('../submissions/starting_kit/external_data.csv')   \n",
    "    # Import holiday data from the holiday.csv file \n",
    "    holidays = pd.read_csv('../data_sources/holidays.csv')\n",
    "    # Import airport data from the airports.csv file \n",
    "    airports = pd.read_csv('../data_sources/airports.csv')\n",
    "    \n",
    "    # Prepare the dates\n",
    "    weather['Date'] = pd.to_datetime(weather['Date'], dayfirst=True)\n",
    "    holidays['Date'] = pd.to_datetime(holidays['Date'], dayfirst=True)\n",
    "    \n",
    "    # Merge weather and holidays dataframes\n",
    "    merge1_data = pd.merge(weather, holidays,\n",
    "                        how='left',\n",
    "                        left_on=['Date'],\n",
    "                        right_on=['Date'],\n",
    "                        sort=False)\n",
    "    \n",
    "    # Merge the previous with airports dataframes for airport coordinates\n",
    "    merge2_data = pd.merge(merge1_data, airports,\n",
    "                        how='left',\n",
    "                        left_on=['AirPort'],\n",
    "                        right_on=['Airport'],\n",
    "                        sort=False)\n",
    "    merge2_data = merge2_data.drop(['Airport'], axis=1)\n",
    "    \n",
    "    # Serialise ext_data to pack it into external_data.csv accepted by the RAMP\n",
    "    merge2_data.to_csv(os.path.join(path, 'external_data.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the following cell executes the scrapper and generates `external_data.csv` in the proper location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scrapper('../submissions/iteration_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Feature extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then propose the following feature extractor.\n",
    "\n",
    "Nevertheless, for some unidentified reason, generating one hot encoding in meteo or holiday events causes the base regressor to throw an error, we deactivated this temporarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../submissions/iteration_0/feature_extractor.py\n"
     ]
    }
   ],
   "source": [
    "%%file ../submissions/iteration_2/feature_extractor.py\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define a mapped version of the Haversine formula to compute distances between airports. \n",
    "# Inspired from https://stackoverflow.com\n",
    "#    /questions/4913349/haversine-formula-in-python-bearing-and-distance-between-two-gps-points\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "def haversine(row):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # we map the rows\n",
    "    lon1 = row['D_lon']\n",
    "    lat1 = row['D_lat']\n",
    "    lon2 = row['A_lon']\n",
    "    lat2 = row['A_lat']\n",
    "    \n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 6371 # Radius of earth in kilometers. Use 3956 for miles\n",
    "    return c * r\n",
    "\n",
    "# Inspired form the feature extractor that comes with starting_kit.\n",
    "class FeatureExtractor(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_df, y_array):\n",
    "        pass\n",
    "\n",
    "    def transform(self, X_df):\n",
    "        X_encoded = X_df\n",
    "\n",
    "        \n",
    "        # Fetches external data from external_data.csv\n",
    "        path = os.path.dirname(__file__)\n",
    "        ext_data = pd.read_csv(os.path.join(path, 'external_data.csv'))\n",
    "        X_ext_data = ext_data[['Date', 'AirPort', 'Max TemperatureC',\n",
    "                               'PaidHoliday', 'FederalHoliday', 'Latitude', 'Longitude']]\n",
    "        \n",
    "        # Merges (left join) fetched external data with base data\n",
    "        X_ext_data = X_ext_data.rename(\n",
    "            columns={'Date': 'DateOfDeparture', 'AirPort': 'Arrival'})\n",
    "        X_encoded = pd.merge(\n",
    "            X_encoded, X_ext_data,\n",
    "            how='left',\n",
    "            left_on=['DateOfDeparture', 'Arrival'],\n",
    "            right_on=['DateOfDeparture', 'Arrival'],\n",
    "            sort=False)\n",
    "        \n",
    "        # Creates one hot encoding for Departure, then drop the original feature\n",
    "        X_encoded = X_encoded.join(pd.get_dummies(\n",
    "            X_encoded['Departure'], prefix='d'))\n",
    "        X_encoded = X_encoded.drop('Departure', axis=1)\n",
    "        \n",
    "        # Creates one hot encoding for Arrival, then drop the original feature\n",
    "        X_encoded = X_encoded.join(pd.get_dummies(\n",
    "            X_encoded['Arrival'], prefix='a'))\n",
    "        X_encoded = X_encoded.drop('Arrival', axis=1)\n",
    "        \n",
    "        #FIXME : for some reason, these treatment raise an error in the regressor like this:\n",
    "        #ValueError: Number of features of the model must match the input.\n",
    "        #Model n_features is 137 and input n_features is 135\n",
    "        #\n",
    "        # Creates one hot encoding for meteo Events, then drop the original feature\n",
    "        #X_encoded['Events'] = X_encoded['Events'].fillna('None')\n",
    "        #X_encoded = X_encoded.join(pd.get_dummies(X_encoded['Events'], prefix='mevent'))\n",
    "        #X_encoded = X_encoded.drop('Events', axis=1)\n",
    "        #\n",
    "        # Creates one hot encoding for Holiday Events, then drop the original feature\n",
    "        #X_encoded['Event'] = X_encoded['Event'].fillna('Ordinary')\n",
    "        #X_encoded = X_encoded.join(pd.get_dummies(X_encoded['Event'], prefix='h'))\n",
    "        #X_encoded = X_encoded.drop('Event', axis=1)\n",
    "        \n",
    "        # Creates one hot encoding for time period likely to catch seasonality\n",
    "        X_encoded['DateOfDeparture'] = pd.to_datetime(X_encoded['DateOfDeparture'])\n",
    "        \n",
    "        X_encoded['weekday'] = X_encoded['DateOfDeparture'].dt.weekday\n",
    "        X_encoded = X_encoded.join(pd.get_dummies(X_encoded['weekday'], prefix='wd'))\n",
    "        X_encoded = X_encoded.drop('weekday', axis=1)\n",
    "        \n",
    "        X_encoded['week'] = X_encoded['DateOfDeparture'].dt.week\n",
    "        X_encoded = X_encoded.join(pd.get_dummies(X_encoded['week'], prefix='w'))\n",
    "        X_encoded = X_encoded.drop('week', axis=1)\n",
    "        \n",
    "        # Drops DateOfDeparture\n",
    "        X_encoded = X_encoded.drop('DateOfDeparture', axis=1)\n",
    "        \n",
    "        # Return the values\n",
    "        X_array = X_encoded.values\n",
    "        return X_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../submissions/iteration_1/feature_extractor.py\n"
     ]
    }
   ],
   "source": [
    "%%file ../submissions/iteration_2/feature_extractor.py\n",
    "import pandas as pd\n",
    "import os\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "# Inspired from https://stackoverflow.com\n",
    "#    /questions/4913349/haversine-formula-in-python-bearing-and-distance-between-two-gps-points\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 6371 # Radius of earth in kilometers. Use 3956 for miles\n",
    "    return c * r\n",
    "\n",
    "\n",
    "# Inspired form the feature extractor that comes with starting_kit.\n",
    "class FeatureExtractor(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_df, y_array):\n",
    "        pass\n",
    "\n",
    "    def transform(self, X_df):\n",
    "        X_encoded = X_df\n",
    "\n",
    "        \n",
    "        # Fetches external data from external_data.csv\n",
    "        path = os.path.dirname(__file__)\n",
    "        ext_data = pd.read_csv(os.path.join(path, 'external_data.csv'))\n",
    "        X_ext_data = ext_data[['Date', 'AirPort', 'Max TemperatureC',\n",
    "                               'PaidHoliday', 'FederalHoliday', 'Latitude', 'Longitude']]\n",
    "        \n",
    "        # Merges (left join) fetched external data with base data\n",
    "        X_encoded = pd.merge(\n",
    "            X_encoded, X_ext_data,\n",
    "            how='left',\n",
    "            left_on=['DateOfDeparture', 'Arrival'],\n",
    "            right_on=['Date', 'AirPort'],\n",
    "            sort=False)\n",
    "        X_encoded = X_encoded.rename(\n",
    "            columns={'Latitude': 'A_lat', 'Longitude': 'A_lon'})\n",
    "        \n",
    "        # Merges (left join) data relevant to departure airport coordinates\n",
    "        X_ext_data_short = X_ext_data[['Date', 'AirPort', 'Latitude', 'Longitude']]\n",
    "        X_encoded = pd.merge(\n",
    "            X_encoded, X_ext_data_short,\n",
    "            how='left',\n",
    "            left_on=['DateOfDeparture', 'Departure'],\n",
    "            right_on=['Date', 'AirPort'],\n",
    "            sort=False)\n",
    "        X_encoded = X_encoded.rename(\n",
    "            columns={'Latitude': 'D_lat', 'Longitude': 'D_lon'})\n",
    "        \n",
    "        # Creates one hot encoding for Departure, then drop the original feature\n",
    "        X_encoded = X_encoded.join(pd.get_dummies(\n",
    "            X_encoded['Departure'], prefix='d'))\n",
    "        X_encoded = X_encoded.drop('Departure', axis=1)\n",
    "        \n",
    "        # Creates one hot encoding for Arrival, then drop the original feature\n",
    "        X_encoded = X_encoded.join(pd.get_dummies(\n",
    "            X_encoded['Arrival'], prefix='a'))\n",
    "        X_encoded = X_encoded.drop('Arrival', axis=1)\n",
    "        \n",
    "        #FIXME : for some reason, these treatment raise an error in the regressor like this:\n",
    "        #ValueError: Number of features of the model must match the input.\n",
    "        #Model n_features is 137 and input n_features is 135\n",
    "        #\n",
    "        # Creates one hot encoding for meteo Events, then drop the original feature\n",
    "        #X_encoded['Events'] = X_encoded['Events'].fillna('None')\n",
    "        #X_encoded = X_encoded.join(pd.get_dummies(X_encoded['Events'], prefix='mevent'))\n",
    "        #X_encoded = X_encoded.drop('Events', axis=1)\n",
    "        #\n",
    "        # Creates one hot encoding for Holiday Events, then drop the original feature\n",
    "        #X_encoded['Event'] = X_encoded['Event'].fillna('Ordinary')\n",
    "        #X_encoded = X_encoded.join(pd.get_dummies(X_encoded['Event'], prefix='h'))\n",
    "        #X_encoded = X_encoded.drop('Event', axis=1)\n",
    "        \n",
    "        # Creates one hot encoding for time period likely to catch seasonality\n",
    "        X_encoded['DateOfDeparture'] = pd.to_datetime(X_encoded['DateOfDeparture'])\n",
    "        \n",
    "        X_encoded['weekday'] = X_encoded['DateOfDeparture'].dt.weekday\n",
    "        X_encoded = X_encoded.join(pd.get_dummies(X_encoded['weekday'], prefix='wd'))\n",
    "        X_encoded = X_encoded.drop('weekday', axis=1)\n",
    "        \n",
    "        X_encoded['week'] = X_encoded['DateOfDeparture'].dt.week\n",
    "        X_encoded = X_encoded.join(pd.get_dummies(X_encoded['week'], prefix='w'))\n",
    "        X_encoded = X_encoded.drop('week', axis=1)\n",
    "        \n",
    "        # Drops DateOfDeparture\n",
    "        X_encoded = X_encoded.drop('DateOfDeparture', axis=1)\n",
    "        \n",
    "        # Computes the distances thanks to Haversine formula\n",
    "        X_encoded['Distances'] = haversine(X_encoded.D_lon,X_encoded.D_lat,X_encoded.A_lon,X_encoded.A_lat)\n",
    "        \n",
    "        # Return the values\n",
    "        X_array = X_encoded.values\n",
    "        return X_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../submissions/iteration_0/regressor.py\n"
     ]
    }
   ],
   "source": [
    "%%file ../submissions/iteration_0/regressor.py\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "\n",
    "class Regressor(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.clf = RandomForestRegressor(\n",
    "            n_estimators=100, max_depth=10, max_features=10)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.clf.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.clf.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Testing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: ramp_test_submission: not found\r\n"
     ]
    }
   ],
   "source": [
    "!cd .. & ramp_test_submission --submission=iteration_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, this provide only a very small improvement with regards to the base estimator as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: ramp_test_submission: not found\r\n"
     ]
    }
   ],
   "source": [
    "!cd .. & ramp_test_submission --submission=starting_kit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>To be continued...</i>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
